{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import skimage.transform\n",
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VGG_NETWORK_NAME = \"vgg\"\n",
    "\n",
    "def load_image(path):\n",
    "    # load image\n",
    "    img = skimage.io.imread(path) / 255.0\n",
    "    assert (0 <= img).all() and (img <= 1.0).all()\n",
    "    # we crop image from center\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy : yy + short_edge, xx : xx + short_edge]\n",
    "    # resize to 224, 224\n",
    "    resized_img = skimage.transform.resize(crop_img, (224, 224))\n",
    "    return resized_img\n",
    "\n",
    "content_image = tf.placeholder(\"float\", [1, 224, 224, 3])\n",
    "style_image = tf.placeholder(\"float\", [1, 224, 224, 3])\n",
    "synthesized_image = tf.Variable(tf.random_uniform([1, 224, 224, 3]), \"synth\")\n",
    "network_input = tf.concat(0, [content_image, style_image, synthesized_image])\n",
    "with open(\"models/vgg16.tfmodel\", mode='rb') as f:\n",
    "            file_content = f.read()\n",
    "graph_def = tf.GraphDef()\n",
    "graph_def.ParseFromString(file_content)\n",
    "tf.import_graph_def(graph_def, input_map={\"images\": network_input}, name=VGG_NETWORK_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from style_helpers import gramian\n",
    "\n",
    "def gramian_for_layer(layer):\n",
    "    \"\"\"\n",
    "    Returns a matrix of cross-correlations between the activations of convolutional channels in a given layer.\n",
    "    \"\"\"\n",
    "    activations = tf.get_default_graph().get_tensor_by_name(\"{0}/conv{1}_1/Relu:0\".format(VGG_NETWORK_NAME, layer))\n",
    "\n",
    "    # Reshape from (batch, width, height, channels) to (batch, channels, width, height)\n",
    "    shuffled_activations = tf.transpose(activations, perm=[0, 3, 1, 2])\n",
    "    return gramian(shuffled_activations)\n",
    "\n",
    "layers = [i for i in range(1, 6)]\n",
    "activations = [tf.get_default_graph().get_tensor_by_name(\"{0}/conv{1}_1/Relu:0\".format(VGG_NETWORK_NAME, i)) for i in layers]\n",
    "gramians = [gramian_for_layer(x) for x in layers]\n",
    "# Slices are for style and synth image\n",
    "gramian_diffs = [tf.sub(tf.slice(g, [1,0,0], [1,-1,-1]), tf.slice(g, [2,0,0], [1,-1,-1])) for g in gramians]\n",
    "Ns = [g.get_shape().as_list()[2] for g in gramians]\n",
    "Ms = [a.get_shape().as_list()[1] * a.get_shape().as_list()[2] for a in activations]\n",
    "scaled_diffs = [tf.square(g) for g in gramian_diffs]\n",
    "style_loss = tf.div(tf.add_n([tf.div(tf.reduce_sum(x), 4*(N**2)*(M**2)) for x, N, M in zip(scaled_diffs, Ns, Ms)]), len(layers))\n",
    "\n",
    "activation_diffs = [tf.sub(tf.slice(a, [0,0,0,0], [1,-1,-1,-1]), tf.slice(a, [2,0,0,0], [1,-1,-1,-1])) for a in activations]\n",
    "content_loss = tf.div(tf.add_n([tf.reduce_sum(tf.square(a)) for a in activation_diffs]), 2.0)\n",
    "\n",
    "alpha = 0.001\n",
    "beta = 1.0\n",
    "combined_loss = tf.add(tf.mul(beta, style_loss), tf.mul(alpha, content_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 7.1462e+09\n",
      "Loss for step 0: 9214424064.0\n",
      "[ 0.22602895  0.25953799  0.55995113]\n",
      "Loss for step 1: 16164547584.0\n",
      "[ 0.26341969  0.28666052  0.58144754]\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.0000001)\n",
    "train_step = optimizer.minimize(combined_loss)\n",
    "style_image_input = load_image(\"img/style.jpg\").reshape((1, 224, 224, 3))\n",
    "content_image_input = load_image(\"img/content.jpg\").reshape((1, 224, 224, 3))\n",
    "print(\"Loss\", sess.run(combined_loss, feed_dict={content_image: content_image_input, style_image: style_image_input}))\n",
    "for i in range(2):\n",
    "    train_step.run(feed_dict={content_image: content_image_input, style_image: style_image_input})\n",
    "    print(\"Loss for step {0}: {1}\".format(i, sess.run(combined_loss, feed_dict={content_image: content_image_input, style_image: style_image_input})))\n",
    "    print(synthesized_image.eval()[0][0][0]) # To make sure it looks reasonable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
